---
title: 'Lab 3: Reserve Planning using prioritizr'
author: "Halina Do-Linh"
date: "1/26/2022"
output:
    html_document:
    toc: true
    toc_float: true
    code_folding: show
---

# Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# 1 Introduction

## 1.2 R packages

```{r}
### run in console only ###

if (!require("librarian")){
  install.packages("librarian")
  library(librarian)
}
librarian::shelf(
  assertthat, BiocManager, dplyr, gridExtra, here, mapview,
  prioritizr, prioritizrdata,
  raster, remotes, rgeos, rgdal, scales, sf, sp, stringr,
  units)
if (!require("lpsymphony")){
  BiocManager::install("lpsymphony")
  library(lpsymphony)
}
```

## 1.3 Data Setup

```{r}
dir_data <- here("data/prioritizr")
pu_shp   <- file.path(dir_data, "pu.shp")
pu_url   <- "https://github.com/prioritizr/massey-workshop/raw/main/data.zip"
pu_zip   <- file.path(dir_data, basename(pu_url))
vegetation_tif <- file.path(dir_data, "vegetation.tif")

dir.create(dir_data, showWarnings = F, recursive = T)
if (!file.exists(pu_shp)){
  download.file(pu_url, pu_zip)
  unzip(pu_zip, exdir = dir_data)
  dir_unzip   <- file.path(dir_data, "data")
  files_unzip <- list.files(dir_unzip, full.names = T)
  file.rename(
    files_unzip, 
    files_unzip %>% str_replace("prioritizr/data", "prioritizr"))
  unlink(c(pu_zip, dir_unzip), recursive = T)
}
```

# Data

## 2.1 Data import

```{r}
# import planning unit data
pu_data <- as(read_sf(pu_shp), "Spatial")

# format columns in planning unit data
pu_data$locked_in <- as.logical(pu_data$locked_in)
pu_data$locked_out <- as.logical(pu_data$locked_out)

# import vegetation data
veg_data <- stack(vegetation_tif)
```

## 2.2 Planning unit data

```{r}
# print a short summary of the data
print(pu_data)
```

```{r}
# plot the planning unit data
plot(pu_data)
```

```{r}
# plot an interactive map of the planning unit data
mapview(pu_data)
```

```{r}
# print the structure of object
str(pu_data, max.level = 2)
```

```{r}
# print the class of the object
class(pu_data)
```

```{r}
# print the slots of the object
slotNames(pu_data)
```

```{r}
# print the coordinate reference system
print(pu_data@proj4string)
```

```{r}
# print number of planning units (geometries) in the data
tot_pu <- nrow(pu_data)
```

```{r}
# print the first six rows in the data
head(pu_data@data)
```

```{r}
# print the first six values in the cost column of the attribute data
head(pu_data$cost)
```

```{r}
# print the highest cost value
max_cost <- max(pu_data$cost)
```

```{r}
# print the smallest cost value
min(pu_data$cost)
```

```{r}
# print average cost value
mean(pu_data$cost)
```

```{r}
# plot a map of the planning unit cost data
spplot(pu_data, "cost")
```

```{r}
# plot an interactive map of the planning unit cost data
mapview(pu_data, zcol = "cost")
```

## Questions

1. How many planning units are in the planning unit data?

**Answer:** There are `r tot_pu` planning units in the planning unit data.

2. What is the highest cost value?

**Answer:** The highest cost value is `r round(max_cost, 2)`.

3. Is there a spatial pattern in the planning unit cost values (hint: use plot to make a map)?

**Answer:** Yes, from the plots you can see that planning unit cost values are significantly lower in the eastern part of southern Tasmania than central or western southern Tasmania.

# 2.3 Vegetation Data

```{r}
# print a short summary of the data
print(veg_data)
```

```{r}
# plot a map of the 20th vegetation class
plot(veg_data[[20]])
```

```{r}
# plot an interactive map of the 20th vegetation class
mapview(veg_data[[20]])
```

```{r}
# print number of rows in the data
nrow(veg_data)
```

```{r}
# print number of columns  in the data
ncol(veg_data)
```

```{r}
# print number of cells in the data
ncell(veg_data)
```

```{r}
# print number of layers in the data
nlayers(veg_data)
```

```{r}
# print resolution on the x-axis
xres(veg_data)
```

```{r}
# print resolution on the y-axis
yres(veg_data)
```

```{r}
# print spatial extent of the grid, i.e. coordinates for corners
extent(veg_data)
```

```{r}
# print the coordinate reference system
print(veg_data@crs)
```

```{r}
# print a summary of the first layer in the stack
print(veg_data[[1]])
```

```{r}
# print the value in the 800th cell in the first layer of the stack
print(veg_data[[1]][800])
```

```{r}
# print the value of the cell located in the 30th row and the 60th column of
# the first layer
print(veg_data[[1]][30, 60])
```

```{r}
# calculate the sum of all the cell values in the first layer
cellStats(veg_data[[1]], "sum")
```

```{r}
# calculate the maximum value of all the cell values in the first layer
cellStats(veg_data[[1]], "max")
```

```{r}
# calculate the minimum value of all the cell values in the first layer
cellStats(veg_data[[1]], "min")
```

```{r}
# calculate the mean value of all the cell values in the first layer
cellStats(veg_data[[1]], "mean")
```

## Questions

4. What part of the study area is the 13th vegetation class found in (hint: make a map)? For instance, is it in the south-eastern part of the study area?

**Answer::** The study area of the 13th vegetation class is in the eastern part of Tasmania and is most dense in the north-east.

```{r}
mapview(veg_data[[13]])
```

5. What proportion of cells contain the 12th vegetation class?

**Answer:** 1.53%

```{r}
freq_12 <- freq(veg_data[[12]])

prop_12 <- freq_12[2,2] / ncell(veg_data[[12]])
```

6. Which vegetation class is the most abundant (i.e. present in the greatest number of cells)?

```{r}
veg_stats <- cellStats(veg_data, "sum", na.rm = TRUE)

veg_max <- which.max(veg_stats)
```

**Answer:** The most abundant vegetation class is `r veg_max`.

# 3 Gap Analysis

## 3.2 Feature Abundance

```{r}
# create prioritizr problem with only the data
p0 <- problem(pu_data, veg_data, cost_column = "cost")

# print empty problem,
# we can see that only the cost and feature data are defined
print(p0)

# calculate amount of each feature in each planning unit
abundance_data <- feature_abundances(p0)

# print abundance data
print(abundance_data)
```

```{r}
# note that only the first ten rows are printed,
# this is because the abundance_data object is a tibble (i.e. tbl_df) object
# and not a standard data.frame object
print(class(abundance_data))
```

```{r}
# we can print all of the rows in abundance_data like this
print(abundance_data, n = Inf)
```


```{r}
# add new column with feature abundances in km^2
abundance_data$absolute_abundance_km2 <-
  (abundance_data$absolute_abundance * prod(res(veg_data))) %>%
  set_units(m^2) %>%
  set_units(km^2)

# print abundance data
print(abundance_data)
```


```{r}
# add new column with feature abundances in km^2
abundance_data$absolute_abundance_km2 <-
  (abundance_data$absolute_abundance * prod(res(veg_data))) %>%
  set_units(m^2) %>%
  set_units(km^2)

# print abundance data
print(abundance_data)
```


```{r}
# calculate the average abundance of the features
mean(abundance_data$absolute_abundance_km2)
```


```{r}
# plot histogram of the features' abundances
hist(abundance_data$absolute_abundance_km2, main = "Feature abundances")
```


```{r}
# find the abundance of the feature with the largest abundance
max(abundance_data$absolute_abundance_km2)
```


```{r}
# find the name of the feature with the largest abundance
abundance_data$feature[which.max(abundance_data$absolute_abundance_km2)]
```

## Questions

7. What is the median abundance of the features (hint: median)?

```{r}
median_feat <- median(abundance_data$absolute_abundance_km2)
```

**Answer:** The median abundance of the features is `r round(median_feat, 2)`.

8. What is the name of the feature with smallest abundance?

```{r}
feat_sm <- abundance_data$feature[which.min(abundance_data$absolute_abundance_km2)]
```

**Answer:** The name of the feature with the smallest abundance is `feat_sm`.

9. How many features have a total abundance greater than 100 km\^2 (hint: use sum(abundance_data\$absolute_abundance_km2 \> set_units(threshold, km\^2) with the correct threshold value)?

**Answer:** Six features have a total abundance greater than 100 $km^2$.

```{r}
abundance_data %>% filter(absolute_abundance_km2 > set_units(100, km^2))
```

## 3.3 Feature representation

```{r}
# create column in planning unit data with binary values (zeros and ones)
# indicating if a planning unit is covered by protected areas or not
pu_data$pa_status <- as.numeric(pu_data$locked_in)

# calculate feature representation by protected areas
repr_data <- eval_feature_representation_summary(p0, pu_data[, "pa_status"])

# print feature representation data
print(repr_data)
```

## Questions

10. What is the average proportion of the features held in protected areas (hint: use mean(table\$relative_held) with the correct table name)?

```{r}
mean_pa <- mean(repr_data$relative_held)
```

**Answer:** The average proportion of the features held in protected areas is `r round(mean_pa, 2)`.

11. If we set a target of 10% coverage by protected areas, how many features fail to meet this target (hint: use sum(table\$relative_held < target_value) with the correct table name)?

```{r}
target_value_10 = 0.10

pa_10 <- sum(repr_data$relative_held >= target_value_10) 
```

**Answer:** `r pa_10` features fail to meet this target.

12. If we set a target of 20% coverage by protected areas, how many features fail to meet this target?

```{r}
target_value_20 = 0.20

pa_20 <- sum(repr_data$relative_held >= target_value_20)
```

**Answer:** `r pa_20` features fail to meet this target.

13. Is there a relationship between the total abundance of a feature and how well it is represented by protected areas (hint: plot(abundance_data$absolute_abundance ~ repr_data$relative_held))?

```{r}
plot(abundance_data$absolute_abundance ~ repr_data$relative_held)
```

**Answer:** There doesn't seem to be a relationship between the total abundance of a feature and how well it is represented by protected areas.


# 4 Spatial prioritizations

## 4.2 Starting out simple

```{r}
# print planning unit data
print(pu_data)
```

```{r}
# make prioritization problem
p1_rds <- file.path(dir_data, "p1.rds")
if (!file.exists(p1_rds)){
  p1 <- problem(pu_data, veg_data, cost_column = "cost") %>%
        add_min_set_objective() %>%
        add_relative_targets(0.05) %>% # 5% representation targets
        add_binary_decisions() %>%
        add_lpsymphony_solver()
  saveRDS(p1, p1_rds)
}
p1 <- readRDS(p1_rds)

# print problem
print(p1)

# solve problem
s1 <- solve(p1)

# print solution, the solution_1 column contains the solution values
# indicating if a planning unit is (1) selected or (0) not
print(s1)
```

```{r}
# calculate number of planning units selected in the prioritization
pu_selected <- eval_n_summary(p1, s1[, "solution_1"])
```

```{r}
# calculate total cost of the prioritization
eval_cost_summary(p1, s1[, "solution_1"])
```

```{r}
# plot solution
# selected = green, not selected = grey
spplot(s1, "solution_1", col.regions = c("grey80", "darkgreen"), main = "s1",
       colorkey = FALSE)
```

## Questions

14. How many planing units were selected in the prioritization? What proportion of planning units were selected in the prioritization?

```{r}
pu_prop_selected <- as.numeric(pu_selected) / length(s1$id)

15 / length(s1$id)
```

**Answer:** There were `r round(pu_prop_selected, 2)` planning units selected in the prioritization.

15. Is there a pattern in the spatial distribution of the priority areas?

**Answer:** I would say there isn't a pattern in the spatial distribution of the priority areas since they are fairly spread out across all of the study area.

16. Can you verify that all of the targets were met in the prioritization (hint: eval_feature_representation_summary(p1, s1[, "solution_1"]))?

**Answer:** Yes you can verify that the 5% target were met in the prioritization since all `relative_held` values are larger than 5%.

```{r}
eval_feature_representation_summary(p1, s1[, "solution_1"])
```

## 4.3 Adding complexity

```{r}
# plot locked_in data
# TRUE = blue, FALSE = grey
spplot(pu_data, "locked_in", col.regions = c("grey80", "darkblue"),
       main = "locked_in", colorkey = FALSE)
```


```{r}
# make prioritization problem
p2_rds <- file.path(dir_data, "p2.rds")
if (!file.exists(p2_rds)){
  p2 <- problem(pu_data, veg_data, cost_column = "cost") %>%
      add_min_set_objective() %>%
      add_relative_targets(0.05) %>%
      add_locked_in_constraints("locked_in") %>%
      add_binary_decisions() %>%
      add_lpsymphony_solver()
  saveRDS(p2, p2_rds)
}
p2 <- readRDS(p2_rds)

# print problem
print(p2)

# solve problem
s2 <- solve(p2)

# plot solution
# selected = green, not selected = grey
spplot(s2, "solution_1", col.regions = c("grey80", "darkgreen"), main = "s2",
       colorkey = FALSE)
```


```{r}
# make prioritization problem
p3_rds <- file.path(dir_data, "p3.rds")
if (!file.exists(p3_rds)){
  p3 <- problem(pu_data, veg_data, cost_column = "cost") %>%
    add_min_set_objective() %>%
    add_relative_targets(0.1) %>%
    add_locked_in_constraints("locked_in") %>%
    add_binary_decisions() %>%
    add_lpsymphony_solver()
  saveRDS(p3, p3_rds)
}
p3 <- readRDS(p3_rds)

# print problem
print(p3)

# solve problem
s3 <- solve(p3)

# plot solution
# selected = green, not selected = grey
spplot(s3, "solution_1", col.regions = c("grey80", "darkgreen"), main = "s3",
       colorkey = FALSE)
```


```{r}
# plot locked_out data
# TRUE = red, FALSE = grey
spplot(pu_data, "locked_out", col.regions = c("grey80", "darkred"),
       main = "locked_out", colorkey = FALSE)
```


```{r}
# make prioritization problem
p4_rds <- file.path(dir_data, "p4.rds")
if (!file.exists(p4_rds)){
  p4 <- problem(pu_data, veg_data, cost_column = "cost") %>%
    add_min_set_objective() %>%
    add_relative_targets(0.1) %>%
    add_locked_in_constraints("locked_in") %>%
    add_locked_out_constraints("locked_out") %>%
    add_binary_decisions() %>%
    add_lpsymphony_solver()
  saveRDS(p4, p4_rds)
}
p4 <- readRDS(p4_rds)

# print problem
print(p4)

# solve problem
s4 <- solve(p4)

# plot solution
# selected = green, not selected = grey
spplot(s4, "solution_1", col.regions = c("grey80", "darkgreen"), main = "s4",
       colorkey = FALSE)
```

## Questions

17. What is the cost of the planning units selected in s2, s3, and s4?

```{r}
s2_cost <- as.numeric(eval_cost_summary(p2, s2[, "solution_1"]))

s3_cost <- as.numeric(eval_cost_summary(p3, s3[, "solution_1"]))

s4_cost <- as.numeric(eval_cost_summary(p4, s4[, "solution_1"]))
```

**Answer:** The cost of the planning units in s2 is `r round(s2_cost, 2)`. The cost of the planning units in s3 is `r round(s3_cost, 2)`. The cost of the planning units in s4 in `r round(s4_cost, 2)`.

18. How many planning units are in s2, s3, and s4?

```{r}
pu_s2 <- eval_n_summary(p2, s2[, "solution_1"])

pu_s3 <- eval_n_summary(p3, s3[, "solution_1"])

pu_s4 <- eval_n_summary(p4, s4[, "solution_1"])
```

**Answer:** There are `r pu_s2` planning units in s2. There are `r pu_s3` planning units in s3. There are `r pu_s4` planning units in s4.

19. Do the solutions with more planning units have a greater cost? Why (or why not)?

**Answers:** The solutions with more planning units have a greater cost because there are more planning units.

20. Why does the first solution (s1) cost less than the second solution with protected areas locked into the solution (s2)?

**Answers:** s1 costs less than s2 because s2 includes the `locked_in` or protected areas in addition to the prioritization planning units. This is an additional constraint to the prioritization, and so this limits the solution and it might have to pick more expensive planning units. 

21. Why does the third solution (s3) cost less than the fourth solution solution with highly degraded areas locked out (s4)?

I assumed that some planning units had higher costs than others so the solution with fewer constraints could pick the cheapest planning units. When more constraints are added, the solution might have to pick more expensive planning units.

**Answers:** s4 has more constraints than s3 and so this means the solution probably has to pick more expensive planning units compared to s3, which had fewer constraints. This hints that the highly degraded areas were of lower cost since those areas were included in s3.

## 4.4 Penalizing fragmentation

```{r}
# make prioritization problem
p5_rds <- file.path(dir_data, "p5.rds")
if (!file.exists(p5_rds)){
  p5 <- problem(pu_data, veg_data, cost_column = "cost") %>%
    add_min_set_objective() %>%
    add_boundary_penalties(penalty = 0.001) %>%
    add_relative_targets(0.1) %>%
    add_locked_in_constraints("locked_in") %>%
    add_locked_out_constraints("locked_out") %>%
    add_binary_decisions() %>%
    add_lpsymphony_solver()
  saveRDS(p5, p5_rds)
}
p5 <- readRDS(p5_rds)

# print problem
print(p5)

# solve problem,
# note this will take a bit longer than the previous runs
s5 <- solve(p5)

# print solution
print(s5)
```


```{r}
# plot solution
# selected = green, not selected = grey
spplot(s5, "solution_1", col.regions = c("grey80", "darkgreen"), main = "s5",
       colorkey = FALSE)
```

## Questions

22. What is the cost of the fourth (s4) and fifth (s5) solutions? Why does the fifth solution (s5) cost more than the fourth (s4) solution?

```{r}
s4_cost <- as.numeric(eval_cost_summary(p4, s4[, "solution_1"]))

s5_cost <- as.numeric(eval_cost_summary(p5, s5[, "solution_1"]))
```

**Answer:** The cost of the s4 soltuion is `r round(s4_cost, 2)` and the cost of the s5 solution is `r round(s5_cost, 2)` We are including a boundary penalty and so this clumps the planning units together which are more expensive than the planning units that would have been chosen without the boundary penalty.

23. Try setting the penalty value to 0.000000001 (i.e. 1e-9) instead of 0.001. What is the cost of the solution now? Is it different from the fourth solution (s4) (hint: try plotting the solutions to visualize them)? Is this is a useful penalty value? Why (or why not)?

```{r}
# make prioritization problem with a penalty value of 1e-9
p6_rds <- file.path(dir_data, "p6.rds")
if (!file.exists(p6_rds)){
  p6 <- problem(pu_data, veg_data, cost_column = "cost") %>%
    add_min_set_objective() %>%
    add_boundary_penalties(penalty = 0.000000001) %>%
    add_relative_targets(0.1) %>%
    add_locked_in_constraints("locked_in") %>%
    add_locked_out_constraints("locked_out") %>%
    add_binary_decisions() %>%
    add_lpsymphony_solver()
  saveRDS(p6, p6_rds)
}
p6 <- readRDS(p6_rds)

# solve problem,
# note this will take a bit longer than the previous runs
s6 <- solve(p6)
```


```{r}
# plot solution
# selected = green, not selected = grey
spplot(s6, "solution_1", col.regions = c("grey80", "darkgreen"), main = "s6",
       colorkey = FALSE)
```

```{r}
s6_cost <- as.numeric(eval_cost_summary(p6, s6[, "solution_1"]))
```

**Answer:** Those cost of s6 is `r round(s6_cost, 2)`, which is slightly higher than s4. s6 and s4 look pretty identical with some slight differences and so because of this, this is not a useful penalty as it doesn't do much.

24. Try setting the penalty value to 0.5. What is the cost of the solution now? Is it different from the fourth solution (s4) (hint: try plotting the solutions to visualize them)? Is this a useful penalty value? Why (or why not)?

```{r}
# make prioritization problem with a penalty value of 0.5
p7_rds <- file.path(dir_data, "p7.rds")
if (!file.exists(p7_rds)){
  p7 <- problem(pu_data, veg_data, cost_column = "cost") %>%
    add_min_set_objective() %>%
    add_boundary_penalties(penalty = 0.5) %>%
    add_relative_targets(0.1) %>%
    add_locked_in_constraints("locked_in") %>%
    add_locked_out_constraints("locked_out") %>%
    add_binary_decisions() %>%
    add_lpsymphony_solver()
  saveRDS(p7, p7_rds)
}
p7 <- readRDS(p7_rds)

# solve problem,
# note this will take a bit longer than the previous runs
s7 <- solve(p7)
```


```{r}
# plot solution
# selected = green, not selected = grey
spplot(s7, "solution_1", col.regions = c("grey80", "darkgreen"), main = "s7",
       colorkey = FALSE)
```


```{r}
s7_cost <- as.numeric(eval_cost_summary(p7, s7[, "solution_1"]))
```


**Answer:** Those cost of s7 is `r round(s7_cost, 2)`, and is much more expensive than s4. s7 and s4 look very different from each other, as s7 looks like one large clump. This is also not a useful penalty because it is including extra planning units we do not need since the minimizing fragmentation is being considered more than the solution cost in this solution. Additionally, the high cost is also not useful. 
